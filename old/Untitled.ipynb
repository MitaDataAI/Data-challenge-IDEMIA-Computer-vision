{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca2b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "# Import required libraries to run the naive baseline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import mobilenet_v3_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea2027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with the mediapipe face mesh pretrained model\n",
    "# download the mediapipe library   \n",
    "# pip install mediapipe\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49bb4bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([     0,      1,      2,      3,      4,      5,      6,      7,      8,\n",
      "            9,\n",
      "       ...\n",
      "       101335, 101336, 101337, 101338, 101339, 101340, 101341, 101342, 101343,\n",
      "       101344],\n",
      "      dtype='int64', length=101341)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>FaceOcclusion</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>database1/img00011271.jpg</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>database1/img00012471.jpg</td>\n",
       "      <td>0.035</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>database1/img00008127.jpg</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>database1/img00008972.jpg</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>database1/img00028187.jpg</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101330</th>\n",
       "      <td>database3/database3/m.01drbr/59-FaceId-0_align...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101331</th>\n",
       "      <td>database3/database3/m.01drbr/69-FaceId-0_align...</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101332</th>\n",
       "      <td>database3/database3/m.01drbr/7-FaceId-0_align.jpg</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101333</th>\n",
       "      <td>database3/database3/m.01drbr/71-FaceId-0_align...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101334</th>\n",
       "      <td>database3/database3/m.01drbr/72-FaceId-0_align...</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101331 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 filename  FaceOcclusion  \\\n",
       "0                               database1/img00011271.jpg          0.019   \n",
       "1                               database1/img00012471.jpg          0.035   \n",
       "2                               database1/img00008127.jpg          0.127   \n",
       "3                               database1/img00008972.jpg          0.014   \n",
       "4                               database1/img00028187.jpg          0.346   \n",
       "...                                                   ...            ...   \n",
       "101330  database3/database3/m.01drbr/59-FaceId-0_align...          0.000   \n",
       "101331  database3/database3/m.01drbr/69-FaceId-0_align...          0.021   \n",
       "101332  database3/database3/m.01drbr/7-FaceId-0_align.jpg          0.008   \n",
       "101333  database3/database3/m.01drbr/71-FaceId-0_align...          0.005   \n",
       "101334  database3/database3/m.01drbr/72-FaceId-0_align...          0.009   \n",
       "\n",
       "        gender  gender_id  \n",
       "0        0.999          1  \n",
       "1        1.000          1  \n",
       "2        0.001          0  \n",
       "3        0.999          1  \n",
       "4        0.982          1  \n",
       "...        ...        ...  \n",
       "101330   1.000          1  \n",
       "101331   0.998          1  \n",
       "101332   1.000          1  \n",
       "101333   1.000          1  \n",
       "101334   0.999          1  \n",
       "\n",
       "[101331 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open df_train.pkl\n",
    "\n",
    "image_dir = \"Data/crops_100K\"\n",
    "df_train = pd.read_csv(\"Data/listes_training/data_100K/train_100K.csv\", delimiter=' ')\n",
    "df_test = pd.read_csv(\"Data/listes_training/data_100K/test_students.csv\", delimiter=' ')\n",
    "\n",
    "# drop the rows where FaceOcclusion is empty & add binary gender column\n",
    "df_train = df_train.dropna(subset=['FaceOcclusion'])\n",
    "df_train['gender_id'] = np.round(df_train['gender'] ).astype(int)\n",
    "\n",
    "# reset the index\n",
    "#df_train = df_train.reset_index(drop=True)\n",
    "print(df_train.index)\n",
    "df_train.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a61203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>database2/database2/test/0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>database2/database2/test/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>database2/database2/test/2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>database2/database2/test/3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>database2/database2/test/4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30497</th>\n",
       "      <td>database3/database3/m.01507p/8-FaceId-0_align.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30498</th>\n",
       "      <td>database3/database3/m.01507p/80-FaceId-0_align...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30499</th>\n",
       "      <td>database3/database3/m.01507p/81-FaceId-0_align...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30500</th>\n",
       "      <td>database3/database3/m.01507p/82-FaceId-0_align...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30501</th>\n",
       "      <td>database3/database3/m.01507p/83-FaceId-0_align...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30502 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                filename\n",
       "0                         database2/database2/test/0.jpg\n",
       "1                         database2/database2/test/1.jpg\n",
       "2                         database2/database2/test/2.jpg\n",
       "3                         database2/database2/test/3.jpg\n",
       "4                         database2/database2/test/4.jpg\n",
       "...                                                  ...\n",
       "30497  database3/database3/m.01507p/8-FaceId-0_align.jpg\n",
       "30498  database3/database3/m.01507p/80-FaceId-0_align...\n",
       "30499  database3/database3/m.01507p/81-FaceId-0_align...\n",
       "30500  database3/database3/m.01507p/82-FaceId-0_align...\n",
       "30501  database3/database3/m.01507p/83-FaceId-0_align...\n",
       "\n",
       "[30502 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('Data/listes_training/data_100K/test_students.csv')\n",
    "df_test = df_test.dropna()\n",
    "df_test.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4deec628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images already processed.\n",
      "Set test_preprocess to \"True\" to process all the images\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/Mediapipe/df_test.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 73\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImages already processed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSet test_preprocess to \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to process all the images\u001b[39m\u001b[38;5;124m'\u001b[39m)   \n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Load the dataframe and the no_face_indices\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/Mediapipe/df_test.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: df_test \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/Mediapipe/test_no_face_indices.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: no_face_indices_test \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_test and no_face_indices_test are loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/Mediapipe/df_test.pkl'"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# PREPROCESSING DES IMAGES TEST ET DATAFRAME TEST\n",
    "########################################################\n",
    "\n",
    "test_preprocess = False # set to True to process all the images\n",
    "img_dir = \"Data/crops_100K\"\n",
    "\n",
    "if test_preprocess == True:\n",
    "    #initialisation\n",
    "    df_test['db_number'] = df_test['filename'].apply(lambda x: (x.split('/')[1])[-1])\n",
    "    df_test['db_number'] = df_test['db_number'].astype(int)\n",
    "    df_test['black_and_white']=0 # 0 = color 1 = black & white\n",
    "    df_test['image_width'] = 0\n",
    "    df_test['image_height'] = 0\n",
    "    df_test['channels'] = 0\n",
    "    df_test['pixels'] = 0\n",
    "    df_test['face'] = 1   # 1 = 1 face detected, 0 = no face detected\n",
    "    df_test['face_pixels'] = 0\n",
    "    df_test['mask_pixels'] = 0\n",
    "    df_test['count'] = 1\n",
    "    test_no_face_indices = []\n",
    "\n",
    "    for i in df_test.index:\n",
    "        if i % 5000 == 0: print(i)\n",
    "\n",
    "        # load image; convert and save information\n",
    "        image = cv2.imread(f\"{image_dir}/{df_test.loc[i]['filename']}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if is_black_and_white(image):\n",
    "            df_test.loc[i, 'black_and_white'] = 1\n",
    "        df_test.loc[i, 'image_width'] = image.shape[0]\n",
    "        df_test.loc[i, 'image_height'] = image.shape[1]\n",
    "        df_test.loc[i, 'pixels'] = image.shape[0] * image.shape[1]\n",
    "        df_test.loc[i, 'channels'] = image.shape[2]\n",
    "\n",
    "        # process image\n",
    "        results = face_mesh.process(image)\n",
    "        mask, skin_area = get_masked_image(image, results)\n",
    "        contours = get_contours(image, results)\n",
    "        mesh = get_mesh(image, results)\n",
    "        cv2.imwrite('Data/Mediapipe/masked_images_test/' + str(i) + '_masked.jpg', cv2.cvtColor(skin_area, cv2.COLOR_RGB2BGR))\n",
    "        cv2.imwrite('Data/Mediapipe/contoured_images_test/' + str(i) + '_mesh.jpg', cv2.cvtColor(contours, cv2.COLOR_RGB2BGR))\n",
    "        cv2.imwrite('Data/Mediapipe/meshed_images_test/' + str(i) + '_contour.jpg', cv2.cvtColor(mesh, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        # save mask information to df and landmarks (if any) to a file\n",
    "        if results.multi_face_landmarks: #face detected\n",
    "\n",
    "            # save mask information\n",
    "            df_test.loc[i, 'face_pixels'] = mask[:,:,0].sum() / 255 # white pixels only ( value = 255) on 1 channel only\n",
    "            df_test.loc[i, 'mask_pixels'] = df_test.loc[i, 'pixels'] - df_test.loc[i, 'face_pixels']\n",
    "\n",
    "            # save landmarks to file\n",
    "            for f, face_landmarks in enumerate(results.multi_face_landmarks):\n",
    "                if f==0:\n",
    "                    landmarks_list = face_landmarks\n",
    "                    with open('Data/Mediapipe/keypoints_test/' + str(i) + '_landmarks.pkl', 'wb') as file:\n",
    "                        pickle.dump(landmarks_list, file)\n",
    "        else:\n",
    "            df_test.loc[i, 'face'] = 0\n",
    "            df_test.loc[i, 'face_pixels'] = df_test.loc[i, 'pixels']\n",
    "            df_test.loc[i, 'mask_pixels'] = 0\n",
    "            test_no_face_indices.append(i)\n",
    "\n",
    "    df_test['color']= df_test['black_and_white'].apply(lambda x: 0 if x == True else 1)\n",
    "    df_test['no_color']= 1 - df_test['color']\n",
    "    # Save the dataframe and the no_face_indices\n",
    "    with open('Data/Mediapipe/df_test_.pkl', 'wb') as f: pickle.dump(df_test, f)\n",
    "    with open('Data/Mediapipe/test_no_face_indices.pkl', 'wb') as f: pickle.dump(test_no_face_indices, f)\n",
    "\n",
    "else :\n",
    "    print('Images already processed.\\nSet test_preprocess to \"True\" to process all the images')   \n",
    "    # Load the dataframe and the no_face_indices\n",
    "    with open('Data/Mediapipe/df_test.pkl', 'rb') as f: df_test = pickle.load(f)\n",
    "    with open('Data/Mediapipe/test_no_face_indices.pkl', 'rb') as f: no_face_indices_test = pickle.load(f)\n",
    "    print(\"df_test and no_face_indices_test are loaded\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07217e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a81633ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set train_preprocess to True to process all the images\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/Mediapipe/df_train.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 79\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSet train_preprocess to True to process all the images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Load the dataframe and the no_face_indices\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/Mediapipe/df_train.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: df_train \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/Mediapipe/train_no_face_indices.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: no_face_indices_train \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_train and no_face_indices_train are loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/Mediapipe/df_train.pkl'"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# PREPROCESSING DES IMAGES TEST ET DATAFRAME TEST\n",
    "# (circa 1 hour with GPU)\n",
    "########################################################\n",
    "\n",
    "train_preprocess = False # set to True to process all the images\n",
    "img_dir = \"Data/crops_100K\"\n",
    "\n",
    "if train_preprocess == True:\n",
    "\n",
    "    #initialisation\n",
    "    df_train['db_number'] = df_train['filename'].apply(lambda x: (x.split('/')[0])[-1])\n",
    "    df_train['db_number'] = df_train['db_number'].astype(int)\n",
    "    df_train['black_and_white']=0 # 0 = color 1 = black & white\n",
    "    df_train['image_width'] = 0\n",
    "    df_train['image_height'] = 0\n",
    "    df_train['channels'] = 0\n",
    "    df_train['pixels'] = 0\n",
    "    df_train['face'] = 1   # 1 = 1 face detected, 0 = no face detected\n",
    "    df_train['face_pixels'] = 0\n",
    "    df_train['mask_pixels'] = 0\n",
    "    df_train['count'] = 1\n",
    "    train_no_face_indices = []\n",
    "\n",
    "    for i in df_train.index:\n",
    "        if i == 100: print(i)\n",
    "        if i == 1000: print(i)\n",
    "        if i % 5000 == 0: print(i)\n",
    "\n",
    "        # load image; convert and save information\n",
    "        image = cv2.imread(f\"{image_dir}/{df_train.loc[i]['filename']}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if is_black_and_white(image):\n",
    "            df_train.loc[i, 'black_and_white'] = 1\n",
    "        df_train.loc[i, 'image_width'] = image.shape[0]\n",
    "        df_train.loc[i, 'image_height'] = image.shape[1]\n",
    "        df_train.loc[i, 'pixels'] = image.shape[0] * image.shape[1]\n",
    "        df_train.loc[i, 'channels'] = image.shape[2]\n",
    "\n",
    "        # process image\n",
    "        results = face_mesh.process(image)\n",
    "        mask, skin_area = get_masked_image(image, results)\n",
    "        contours = get_contours(image, results)\n",
    "        mesh = get_mesh(image, results)\n",
    "        cv2.imwrite('Data/Mediapipe/masked_images/' + str(i) + '_masked.jpg', cv2.cvtColor(skin_area, cv2.COLOR_RGB2BGR))\n",
    "        cv2.imwrite('Data/Mediapipe/contoured_images/' + str(i) + '_mesh.jpg', cv2.cvtColor(contours, cv2.COLOR_RGB2BGR))\n",
    "        cv2.imwrite('Data/Mediapipe/meshed_images/' + str(i) + '_contour.jpg', cv2.cvtColor(mesh, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        # save mask info in df and landmarks  (if any) to a file\n",
    "        if results.multi_face_landmarks: #face detected\n",
    "\n",
    "            # save mask information\n",
    "            df_train.loc[i, 'face_pixels'] = mask[:,:,0].sum() / 255 # white pixels only ( value = 255) on 1 channel only\n",
    "            df_train.loc[i, 'mask_pixels'] = df_train.loc[i, 'pixels'] - df_train.loc[i, 'face_pixels']\n",
    "\n",
    "            # save landmarks to file\n",
    "            for f, face_landmarks in enumerate(results.multi_face_landmarks):\n",
    "                if f==0:\n",
    "                    landmarks_list = face_landmarks\n",
    "                    with open('Data/Mediapipe/keypoints/' + str(i) + '_landmarks.pkl', 'wb') as file:\n",
    "                        pickle.dump(landmarks_list, file)\n",
    "\n",
    "        else:\n",
    "            df_train.loc[i, 'face'] = 0\n",
    "            df_train.loc[i, 'face_pixels'] = df_train.loc[i, 'pixels']\n",
    "            df_train.loc[i, 'mask_pixels'] = 0\n",
    "            train_no_face_indices.append(i)\n",
    "\n",
    "    df_train['color']= df_train['black_and_white'].apply(lambda x: 0 if x == True else 1)\n",
    "    df_train['no_color']= 1 - df_train['color']\n",
    "\n",
    "    # Save the dataframe and the no_face_indices\n",
    "    with open('Data/Mediapipe/df_train_.pkl', 'wb') as f: pickle.dump(df_train, f)\n",
    "    with open('Data/Mediapipe/train_no_face_indices_.pkl', 'wb') as f: pickle.dump(train_no_face_indices, f)\n",
    "\n",
    "else:\n",
    "    print(\"Set train_preprocess to True to process all the images\")\n",
    "    # Load the dataframe and the no_face_indices\n",
    "    with open('Data/Mediapipe/df_train.pkl', 'rb') as f: df_train = pickle.load(f)\n",
    "    with open('Data/Mediapipe/train_no_face_indices.pkl', 'rb') as f: no_face_indices_train = pickle.load(f)\n",
    "    print(\"df_train and no_face_indices_train are loaded\")  \n",
    "\n",
    "df_train.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4fec40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a1356a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FaceOcclusion</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>101341.000000</td>\n",
       "      <td>101341.000000</td>\n",
       "      <td>101341.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.087769</td>\n",
       "      <td>0.599738</td>\n",
       "      <td>0.601080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.090530</td>\n",
       "      <td>0.486110</td>\n",
       "      <td>0.489679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.131000</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       FaceOcclusion         gender      gender_id\n",
       "count  101341.000000  101341.000000  101341.000000\n",
       "mean        0.087769       0.599738       0.601080\n",
       "std         0.090530       0.486110       0.489679\n",
       "min         0.000000       0.000000       0.000000\n",
       "25%         0.019000       0.001000       0.000000\n",
       "50%         0.054000       0.996000       1.000000\n",
       "75%         0.131000       0.999000       1.000000\n",
       "max         1.000000       1.000000       1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train.describe()\n",
    "# with open('Data/Mediapipe/df_train.pkl', 'wb') as f: pickle.dump(df_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c80f534",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'db_number'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stats_train \u001b[38;5;241m=\u001b[39m df_train\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdb_number\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_color\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m      2\u001b[0m stats_train\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m stats_train\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# add column with percentage of no color images\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   8870\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   8871\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[0;32m   8872\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   8873\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   8874\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[0;32m   8875\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   8876\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[0;32m   8877\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[0;32m   8878\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[0;32m   8879\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[0;32m   1279\u001b[0m         obj,\n\u001b[0;32m   1280\u001b[0m         keys,\n\u001b[0;32m   1281\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   1282\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   1283\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   1284\u001b[0m         observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[0;32m   1285\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[0;32m   1286\u001b[0m     )\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'db_number'"
     ]
    }
   ],
   "source": [
    "stats_train = df_train.groupby('db_number')['count','color','no_color'].sum()\n",
    "stats_train.loc['total'] = stats_train.sum()\n",
    "# add column with percentage of no color images\n",
    "stats_train['no_color_%'] = stats_train['no_color'] / stats_train['count'] * 100\n",
    "stats_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
